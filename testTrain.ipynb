{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This part of the code is the core part of the test network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Configuration import printPeriodic,setDbgPrint,null\n",
    "from data_Generator import data_Generator\n",
    "import io, os, sys, types\n",
    "from Utils import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class runTest():\n",
    "    def __init__(self ):\n",
    "        self.actions = [\n",
    "            \"Channel_1\",\n",
    "            \"Channel_6\",\n",
    "            \"Channel_11\"\n",
    "        ]\n",
    "        self.n_actions = len(self.actions)\n",
    "        self.n_features = 3\n",
    "        self.built_net()\n",
    "        self.sess = tf.Session()\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.saver.restore(self.sess, 'my_net/my_test_model.ckpt') #Load parameter\n",
    "        self.params = []\n",
    "        self.cost_his = []\n",
    "        self.time = 0\n",
    "        self.time_env_state = {}\n",
    "        self.num = 0\n",
    "        self.list = data_Generator()\n",
    "        self.reward_history = []\n",
    "        self.action_history = []\n",
    "    def built_net(self):\n",
    "        tf.reset_default_graph()\n",
    "        # Reconstruction neural network model.Only one of the neural networks is kept here.\n",
    "        c_names, n_l1, w_initializer, b_initializer = ['target_net_params', tf.GraphKeys.GLOBAL_VARIABLES], 10, \\\n",
    "                                                      tf.random_normal_initializer(0., 0.3), tf.constant_initializer(0.1)\n",
    "        self.env_state_ = tf.placeholder(tf.float32, [None, self.n_features], name='env_state_')\n",
    "        with tf.variable_scope('target_net'):\n",
    "            c_names = ['target_net_params', tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "\n",
    "            with tf.variable_scope(\n",
    "                    'l1'):\n",
    "                w1 = tf.get_variable('w1', [self.n_features, n_l1], initializer=w_initializer, collections=c_names)\n",
    "                b1 = tf.get_variable('b1', [1, n_l1], initializer=b_initializer, collections=c_names)\n",
    "                l1 = tf.nn.tanh(tf.matmul(self.env_state_, w1) + b1)\n",
    "            with tf.variable_scope('l2'):\n",
    "                w2 = tf.get_variable('w2', [n_l1, self.n_actions], initializer=w_initializer, collections=c_names)\n",
    "                b2 = tf.get_variable('b2', [1, self.n_actions], initializer=b_initializer, collections=c_names)\n",
    "                self.q_next = tf.matmul(l1, w2) + b2\n",
    "\n",
    "    def choose_action(self, env_state):\n",
    "        env_state = env_state[np.newaxis, :]\n",
    "        actions_value = self.sess.run(self.q_next,feed_dict={self.env_state_: env_state})\n",
    "        action = np.argmax(actions_value)\n",
    "        return action\n",
    "    def data(self):\n",
    "\n",
    "        channel = self.list[self.num]\n",
    "        self.num +=1\n",
    "        return channel\n",
    "\n",
    "    def reset(self):\n",
    "        self.update_State()\n",
    "        # self.state = \"Channel_1\"\n",
    "        return self.time_env_state[\"current\"]\n",
    "\n",
    "\n",
    "    def update_State(self):\n",
    "        self.time += 1\n",
    "        filename = 'data.csv'\n",
    "\n",
    "        self.time_env_state[\"current\"] = {\"Channel_1\": self.data(),\n",
    "                                          \"Channel_6\": self.data(),\n",
    "                                          \"Channel_11\": self.data(), }\n",
    "\n",
    "        return self.time_env_state[\"current\"]\n",
    "    def step(self,action):\n",
    "        value = 0\n",
    "        min_value = np.Inf\n",
    "        action_key = \"\"\n",
    "\n",
    "       # self.log('{}: action {} has min. value {}\\n'.format(self.time, action_key, min_value), period=self.statusPeriod,\n",
    "                # counter=self.time)\n",
    "\n",
    "\n",
    "        for key in self.time_env_state[\"current\"]:\n",
    "\n",
    "            value = self.time_env_state[\"current\"][key][0]\n",
    "            if value < min_value:\n",
    "                min_value = value\n",
    "                action_key = key\n",
    "        #reward = self.reward(action)\n",
    "        if action_key == action:\n",
    "            self.reward = 5\n",
    "        else:\n",
    "            self.reward = 0\n",
    "        self.reward_history.append(self.reward)\n",
    "        # self.correct_rate.append(self.count/(len(self.count_history)))\n",
    "        next_state = action\n",
    "        self.state = next_state\n",
    "        self.update_State()\n",
    "\n",
    "        return self.time_env_state[\"current\"], self.time_env_state[\"current\"][next_state]\n",
    "    def run_(self,cfg=None):\n",
    "        numEpisodes = cfg['numEpisodes']\n",
    "        maxSteps = cfg['maxStepsTest']\n",
    "        dbgPrint = cfg.get('dbgPrint', null)\n",
    "\n",
    "        statusPeriod = cfg.get('statusPeriod', 1)\n",
    "        for episode in range(1,numEpisodes+1):\n",
    "            # initial observation\n",
    "            step = 0\n",
    "            env_state_1 = self.reset()\n",
    "            while step < maxSteps:\n",
    "                print('{}: current env = {}\\n'.format(self.time, self.time_env_state))\n",
    "                env_state = np.hstack((env_state_1[\"Channel_1\"], env_state_1[\"Channel_6\"],\n",
    "                                       env_state_1[\"Channel_11\"]))\n",
    "\n",
    "                action = self.choose_action(env_state)\n",
    "                if action == 0:\n",
    "                    action_ = \"Channel_1\"\n",
    "                    self.action_history.append(1)\n",
    "                elif action == 1:\n",
    "                    action_ = \"Channel_6\"\n",
    "                    self.action_history.append(6)\n",
    "                else:\n",
    "                    action_ = \"Channel_11\"\n",
    "                    self.action_history.append(11)\n",
    "                observation = env_state_1[action_]\n",
    "                dbgPrint('{}: action_ = {}, observation = {}\\n'.format(self.time, action_, observation),\n",
    "                         period=statusPeriod, counter=self.time)\n",
    "                print('{}: action_ = {}, observation = {}\\n'.format(self.time, action_, observation))\n",
    "                env_state_, observation_ = self.step(action_)\n",
    "                env_state_ = np.hstack(( env_state_[\"Channel_1\"],  env_state_[\"Channel_6\"],\n",
    "                                env_state_[\"Channel_11\"]))\n",
    "                env_state_ = {\"Channel_1\": env_state_[0:1],\n",
    "                              \"Channel_6\": env_state_[1:2],\n",
    "                              \"Channel_11\": env_state_[2:3]\n",
    "\n",
    "                              }\n",
    "                env_state_1 = env_state_\n",
    "                step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
